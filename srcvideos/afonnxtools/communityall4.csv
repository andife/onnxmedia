tags	Title	Speaker	Description	Video_Url	Video_Url2	related_urls	recorded	language	folder
h	ONNX Steering Committee Update	Prasanth Pulavarthi (Microsoft), Alexandre Eichenberger (IBM), Rajeev Nalawadi (Intel), Mayank Kaushik (NVIDIA), Andreas Fehlner (TRUMPF Laser GmbH)		https://youtu.be/3vLtVL5n1y4	https://wiki.lfaidata.foundation/download/attachments/61964495/01video_SteeringCommittee.mp4?version=1&modificationDate=1657218148000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/01_SteeringCommittee.pdf?version=1&modificationDate=1657154266000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, SIG	ONNX SIG: Arch & Infra	Liqun Fu (Microsoft)		https://youtu.be/rervhzv8C1c	https://wiki.lfaidata.foundation/download/attachments/61964495/sig-wg-updated-infa.mp4?version=1&modificationDate=1657639479000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/02_ArchInfra.pdf?version=1&modificationDate=1657154284000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, Operators	ONNX SIG: Operators	Ganesan Ramalingam (Microsoft)		https://youtu.be/rervhzv8C1c?t=317	https://wiki.lfaidata.foundation/download/attachments/61964495/sig-wg-updated-ops.mp4?version=1&modificationDate=1657639479000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/03_Operators.pdf?version=1&modificationDate=1657154297000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, converters	ONNX SIG: Converters	Kevin Chen (NVIDIA)		https://youtu.be/rervhzv8C1c?t=873	https://wiki.lfaidata.foundation/download/attachments/61964495/sig-wg-updated-converter.mp4?version=1&modificationDate=1657639479000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/04_Converters.pdf?version=1&modificationDate=1657154304000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, models, tutorials	ONNX SIG: Model & Tutorials	Jacky Chen (Microsoft)		https://youtu.be/rervhzv8C1c?t=1388	https://wiki.lfaidata.foundation/download/attachments/61964495/sig-wg-updated-zoo.mp4?version=1&modificationDate=1657639467000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/05_Model%26Tutorial.pdf?version=1&modificationDate=1657154311000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, Pre-processing	ONNX WG: Pre-processing	Joaquin Anton (NVIDIA)		https://youtu.be/rervhzv8C1c?t=1909	https://wiki.lfaidata.foundation/download/attachments/61964495/06video_Preprocessing.mp4?version=1&modificationDate=1657154328000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/06_Preprocessing.pdf?version=2&modificationDate=1657225586000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, optimization	Designed to be Optimized	Mauro Bennici (GhostWriter.AI)	ONNX Runtime allows us to export our models for different platforms and systems. Optimization, however, starts with design. Leaving it when everything seems ready to go a production could make effective optimization impossible. We will see the frequent mistakes and how to avoid them. \n\n\n	https://youtu.be/2cMJrba4Pp8	https://wiki.lfaidata.foundation/download/attachments/61964495/01video_GhostwriterAI.mp4?version=1&modificationDate=1657217407000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/01_GhostwriterAI.pdf?version=1&modificationDate=1657154865000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, int8, qat, tensorrt	INT8 Inference of Quantization-Aware trained models using ONNX-TensorRT	Dheeraj Peri (NVIDIA)	Accelerating Deep Neural Networks (DNN) inference is an important step in realizing latency-critical deployment of real-world applications such as image classification, image segmentation, natural language processing, etc. The need to improve DNN's inference latency has sparked interest in running those models in lower precisions, such as FP16 and INT8. In particular, running DNNs in INT8 precision can offer faster inference and a much lower memory footprint than its floating-point counterpart. NVIDIA TensorRT supports Quantization-Aware Training (QAT) techniques to convert floating-point DNN models to INT8 precision. In this talk, we shall demonstrate end-end workflow of converting Tensorflow QAT models into ONNX, which is a standard intermediate representation to deploy using TensorRT. We use TF2ONNX package to convert a quantized Tensorflow model into ONNX. ONNX format makes it easier to visualize graphs via netron which can provide users information about placement of quantized nodes. 	https://www.youtube.com/watch?v=WEqzbBDqs2I	https://wiki.lfaidata.foundation/download/attachments/61964495/02video_NVIDIA_TensorRT.mp4?version=1&modificationDate=1657155092000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/02_NVIDIA_TensorRT.pdf?version=1&modificationDate=1657155078000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06,, qonnx	QONNX: A proposal for representing arbitrary-precision quantized NNs in ONNX	Alessandro Pappalardo (AMD)	We present extensions to the Open Neural Network Exchange (ONNX) intermediate representation format to represent arbitrary-precision quantized neural networks. We first introduce support for low precision quantization in existing ONNX-based quantization formats by leveraging integer clipping, resulting in two new backward-compatible variants: the quantized operator format with clipping and quantize-clip-dequantize (QCDQ) format. We then introduce a novel higher-level ONNX format called quantized ONNX (QONNX) that introduces three new operators —Quant, BipolarQuant, and Trunc— in order to represent uniform quantization. By keeping the QONNX IR high-level and flexible, we enable targeting a wider variety of platforms. We also present utilities for working with QONNX, as well as examples of its usage in the FINN and hls4ml toolchains. Finally, we introduce the QONNX model zoo to share low precision quantized neural networks. 	https://youtu.be/b0ik9tDMJlg	https://wiki.lfaidata.foundation/download/attachments/61964495/amd-updated.mp4?version=1&modificationDate=1657637684000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/03_AMD.pdf?version=1&modificationDate=1657155097000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, privacy	How to reconcile AI and privacy	Daniel Huynh (Mithril Security)	AI is revolutionising many fields from healthcare to biometrics these recent years. However due to security and privacy concerns, data is still being siloed and not shared enough due to the fear of data exposure and IP leakage. Confidential Computing is a recent technology that enables end-to-end encryption when analysing sensitive data. By leveraging Confidential Computing, data owners can share their data to AI companies, for instance to train or consume an AI model, without ever risking their data being stolen, leaked or used for any other purpose, as data remains protected even when shared to third parties. This talk aims to introduce the high level principles of Confidential Computing and how it can be used to deploy privacy friendly AI models. We will present BlindAI, an AI deployment solution, serving ONNX models with privacy guarantees, and see how it can be used to unlock confidential medical document analysis in the Cloud, or facial recognition with privacy guarantees. 	https://youtu.be/OXrSvTG9310	https://wiki.lfaidata.foundation/download/attachments/61964495/mithrilsecurity-updated.mp4?version=1&modificationDate=1657640911000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/04_MithrilSecurity.pdf?version=1&modificationDate=1657155109000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, responsible AI, metadata, model card, provenance	Responsible AI @ ONNX: Metadata, Model Cards, and Provenance 	Rodolfo Gabe Esteves (Intel), Bhargavi Karumanchi (Intel), Ria Cheruvu (Intel), Rajeev Nalawadi (Intel) 	The space of AI is growing rapidly. At this pace, it can be challenging for key AI stakeholders to identify and address social and regulatory concerns with AI, motivating the need for tools and methods to approach AI ethics challenges. A popular approach in the responsible AI space is using metadata to encode a “model card,” a versatile report detailing the configuration, ethical considerations, limitations, and quantitative analysis of an AI model. This approach can be used to enable transparency and fairness of the use case, filtering of high-quality AI models, pain point identification in AI pipelines, and help with establishing compliance and lineage. In this session, we will present our proposal and end-to-end proof of concept for metadata fields and model cards incorporated in Onnx to capture aspects of the model such as provenance & mixed precision representation. 	https://youtu.be/U6L-bBKApA4	https://wiki.lfaidata.foundation/download/attachments/61964495/intel-updated.mp4?version=1&modificationDate=1657642990000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/05_Intel.pdf?version=1&modificationDate=1657155276000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, onnx, jvm	ONNX and the JVM	Adam Pocock (Oracle)	Integrating machine learning into enterprises requires building and deploying ML models in the environments enterprises build their software in. Frequently this is in Java, or another language running on the JVM. In this talk we'll cover some of our recent work bringing the ONNX ecosystem to Java. We'll discuss uses of ONNX Runtime from Java, and also our work writing model converters from our Java ML library into ONNX format. 	https://youtu.be/hyPNMjHEYwA	https://wiki.lfaidata.foundation/download/attachments/61964495/oracle-updated_lower.mp4?version=1&modificationDate=1657650773000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/06_Oracle.pdf?version=1&modificationDate=1657155285000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, High-performance, djl	Build your high-performance model inference solution with DJL and ONNX Runtime	Qing Lan (AWS)	In many companies, Java is the primary language for the teams to build up services. To have ONNX model onboard and integration, developers faced several technical challenges on the resource allocation and performance tuning. In this talk, we will walk you through the inference solution built by DJL, a ML library in Java. In the meantime, we will share some customer success stories with model hosting using ONNXRuntime and DJL. 	https://youtu.be/aTAwpfK_bdE	https://wiki.lfaidata.foundation/download/attachments/61964495/07video_AWS.mp4?version=1&modificationDate=1657214908000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/07_AWS.pdf?version=1&modificationDate=1657155294000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, nlp	Billions of NLP Inferences on the JVM using ONNX and DJL	Viet Yen Nguyen (Hypefactors)	This session outlines the recently rolled out Hypefactors' MLOps infrastructure designed for billions NLP inferences a day. The workload serves media intelligence and OSINT use cases. The infrastructure is designed with a Java Virtual Machine-first approach that is enabled by ONNX interop and AWS' Deep Java Library. On top of that, we show how quantization drives further performance optimizations. 	https://youtu.be/NC-D_r4a-u8	https://wiki.lfaidata.foundation/download/attachments/61964495/hypefactors-updated.mp4?version=2&modificationDate=1657651218000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/08_Hypefactors.pdf?version=1&modificationDate=1657155303000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, onnx, runtime	What's New in ONNX Runtime	Ryan Hill (Microsoft)	This talk will share highlights of the ONNX Runtime 1.10-1.12 releases, including details on notable performance improvements, features, and platforms including mobile and web. 	https://youtu.be/uOE2K-yfnOU	https://wiki.lfaidata.foundation/download/attachments/61964495/microsoftryan-updated.mp4?version=1&modificationDate=1657651522000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/09_Microsoft_ONNXRuntime.pdf?version=1&modificationDate=1657155312000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, hugging face, onnx, runtime	Accelerating Machine Learning with ONNX Runtime and Hugging Face	Jeff Boudier (Hugging Face)	Hugging Face has democratized state of the art machine learning with Transformers and the Hugging Face Hub, but deploying these large and complex models into production with good performance remains a challenge for most organizations. In this talk, Jeff Boudier will talk you through the latest solutions from Hugging Face to deploy models at scale with great performance leveraging ONNX and ONNX Runtime.	https://youtu.be/9H7biU4eLZY	https://wiki.lfaidata.foundation/download/attachments/61964495/huggingface-updated_2.mp4?version=1&modificationDate=1657730389000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/10_HuggingFace.pdf?version=1&modificationDate=1657155322000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, pytorch, converter	PyTorch-ONNX Converter	Bowen Bao (Microsoft)	This session will present an overview of the PyTorch-ONNX converter, its implementation, and recent improvements to support a wide range of models.	https://youtu.be/R2mUT_s0PbE	https://wiki.lfaidata.foundation/download/attachments/61964495/microsoftbowen-updated.mp4?version=1&modificationDate=1657639709000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/11_Microsoft_PyTorchConverter.pdf?version=1&modificationDate=1657155333000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, safety 	Detect Safety Zone Violation in Manufacturing with SAS Event Stream Processing and ONNX models	Allen Langlois (SAS), Saurabh Mishra (SAS), Daniele Cazzari (SAS)	This session will present an in-production solution that takes advantage of SAS Event Stream Processing and ONNX runtime to support the detection of safety zone violations using computer vision pre-trained ONNX Model and involving multiple cameras. This solution was deployed at the factory edge with an architecture that, using Kubernetes and Kafka, ensures a reliable and stable environment for productionized computer vision solutions complemented with a cloud-centralized infrastructure to monitor, manage and collect information from multiple factories 	https://youtu.be/i1lLSf_7rjw	https://wiki.lfaidata.foundation/download/attachments/61964495/12video_SAS.mp4?version=1&modificationDate=1657155704000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/12_SAS.pdf?version=1&modificationDate=1657155342000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, onnx	Improving the online shopping experience with ONNX	Mtthew Leyburn (Bazaarvoice)	Building and deploying AI solutions to the cloud at scale is complex. With massive datasets and performance considerations - finding a harmonious balance is crucial. This session will outline key learnings from deploying a Serverless application running inference on a sci-kit learn model using ONNX Runtime, and will share how to utilize the capabilities of ONNX runtime to improve the online shopping experience for shoppers and global brands. 	https://youtu.be/dRdpTayIkGc	https://wiki.lfaidata.foundation/download/attachments/61964495/13video_Bazaarvoice.mp4?version=1&modificationDate=1657155714000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/13_Bazaarvoice.pdf?version=1&modificationDate=1657155679000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, High-performance, video, audio	High-Performance Inference for Video and Audio	Nikhil Kalra (Adobe)	ORT provides the foundations for inference for Adobe's audio and video products (Premiere Pro, After Effects, Character Animator) on both Mac and Windows. In this talk, we'll discuss how ORT with the DML backend is essential in enabling high-throughput inference for audio and video workflows on Windows, and how we use ORT to enable speech to text on Mac. Video workflows are unique because of the sheer amount of data they process; our customers frequently ingest high resolution video >= 4k@60fps of which each frame may need to be passed through our models. Likewise, video workflows are inherently resource limited: the GPU is also being used for hardware decode and render at the same time. ORT gives us the tools to build complex frameworks and workflows on top of so that we can deliver ML-based features while ensuring that we're able to provide the best experience for our customers. 	https://youtu.be/I8Mvx91NvEc	https://wiki.lfaidata.foundation/download/attachments/61964495/14video_Adobe.mp4?version=1&modificationDate=1657155731000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/14_Adobe.pdf?version=1&modificationDate=1657155692000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, onnx	Deploying on Desktop with ONNX	Alexander Zhang (Topaz Labs)	ORT provides the foundations for inference for Adobe's audio and video products (Premiere Topaz Labs develops deep learning based image quality software for professional and hobbyist photographers, which means running on the user's desktop or laptop. ONNX is an essential part of our solution to producing consistent results while making the most of a variety of consumer hardware. This type of deployment poses unique challenges and opportunities. Some experiences in this task have driven us to adopt certain useful strategies, tools, and techniques. Others remain interesting avenues for future improvement. 	https://youtu.be/FGTe9XsrwAU	https://wiki.lfaidata.foundation/download/attachments/61964495/topazlabs-updated.mp4?version=1&modificationDate=1657656763000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/15_TopazLabs.pdf?version=1&modificationDate=1657155733000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, onnx, tools, graphsurgeon	ONNX Tools: Polygraphy and ONNX-GraphSurgeon	Pranav Marathe (NVIDIA)	Over the years, NVIDIA's TensorRT team has developed tooling that makes it easy to generate, transform, and debug ONNX models. Among other things, this includes a sanitizer that can simplify your models, and an automated bisector for debugging ('git bisect' for ONNX!). In this talk, I'll cover some of these tools and how you can effectively leverage them in your workflow.	https://youtu.be/OGMan5SQzhM	https://wiki.lfaidata.foundation/download/attachments/61964495/16video_NVIDIA_GraphSurgeon.mp4?version=1&modificationDate=1657155757000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/16_NVIDIA_GraphSurgeon.pdf?version=1&modificationDate=1657155746000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, edge	Using ONNX with Qualcomm powered devices from smartphones to the cloud edge and everything in between.	Felix Baum (Qualcomm)	Whenever our clients target high performant AI cloud inferencing servers, create new and exciting AI based experiences on mobile phones or improve our lives by adding more and more AI features into cars, many of them use ONNX models as an interchange format. Qualcomm helps to deploy and accelerate natural language processing, computer vision, classification, segmentation, and transformer based models in various verticals: Mobile, IoT, XR, Compute and Automotive. We created a link between ONNX and Qualcomm AI Engine direct that allows us to run the same model not only on various backends such as CPU, GPU, Hexagon processor or Low Power AI subsystem of the same SoC, and migrate it to run on range of the devices due to the portability that ONNX provides. In addition to the above, we would briefly cover in this session the work we are doing with Microsoft on collaboration for ONNX RT Execution Provider for a range of our AI accelerators. 	https://youtu.be/bcnaShCscoM	https://wiki.lfaidata.foundation/download/attachments/61964495/qualcomm-updated_2.mp4?version=1&modificationDate=1657653030000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/17_Qualcomm.pdf?version=1&modificationDate=1657155763000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, mlir	Onnx-mlir: an MLIR-based Compiler for ONNX Models - The Latest Status	Tung D. Le (IBM)	Onnx-mlir is an open source compiler implemented using the Multi-Level Intermediate Representation (MLIR) infrastructure recently integrated in the LLVM project. It compiles ONNX models into native code for CPUs as well as specialized accelerators. It is able to compile models for many platforms including x86 (Linux/Windows/macOS), Power (Linux) and z/Architecture (Linux and z/OS). Onnx-mlir is a subproject inside the ONNX ecosystem and has attracted many contributions from IBM, Microsoft, Facebook, Arm and Universities since its incubation in 2019. In this talk, we will show the latest status of the project by providing the project overview as well as the latest features. 	https://youtu.be/V70XXsPVrzg	https://wiki.lfaidata.foundation/download/attachments/61964495/ibm-updated.mp4?version=1&modificationDate=1657653347000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/18_IBM.pdf?version=1&modificationDate=1657155776000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, pfvm	PFVM - A Neural Network Compiler that uses ONNX as its intermediate representation	Zijian Xu (Preferred Networks)	PFVM is a neural network compiler developed by Preferred Networks, which relies on ONNX as the Intermediate Representation format. PFVM is used in production environments to deploy models to various devices such as GPUs, multiple edge computing architectures, and PFN's own accelerator, MN-Core. PFVM's most salient features are; automatic checkpointing, operator fusion, and graph simplification that can be applied even when models have dynamic axes or unknown shapes. ONNX Shape inference becomes a critical element for all these optimizations, and the importance of bringing up more advanced shape inference mechanisms to address complex optimization scenarios is discussed in this talk.	https://youtu.be/Gr3o2WQmNDY	https://wiki.lfaidata.foundation/download/attachments/61964495/preferrednetworks-updated_1.mp4?version=1&modificationDate=1657654246000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/19_PreferredNetworks.pdf?version=1&modificationDate=1657155786000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
Onnxcommunityday-2022_06, spark	Bring the power of ONNX to Spark as it never happened before	Xiyuan Wang (Huawei), Yikun Jiang (Huawei), Zhipeng Huang (Huawei) 	Both data processing platforms and deep learning frameworks are evolving in their own fields. Usually, Spark is used for offline data processing, and then various deep learning frameworks are used for data inference. A simplified API for DL Inferencing is very important as a bridge. What does an ideal data and deep learning inference pipeline look like? We'll discuss how to build your AI application using Spark and ONNX, the current status and initial idea of Spark community to improve this pipeline, and also make full use of the capabilities of Ascend Hardware Platform. This topic help you know the latest progress of Ascend Hardware Platform integration in ONNX, as well as the initial idea of the inference pipeline improvement in the Spark community. 	https://youtu.be/khM13V4oiKE	https://wiki.lfaidata.foundation/download/attachments/61964495/20video_Huawei.mp4?version=1&modificationDate=1657155829000&api=v2	"""label"": ""Presentation (PDF)"", ""url"":  ""https://wiki.lfaidata.foundation/download/attachments/61964495/20_Huawei.pdf?version=1&modificationDate=1657155796000&api=v2"""	2022-06-24	eng	onnxcommunity-2022_06
welcome	Welcome and opening	Ti Zhou (Baidu)		http://youtu.be/ta9sBtL-4LQ			2021-03-24	eng	onnxcommunity-2021_03
Steering Committee	SteeringCommitteeUpdates: Stats and Community	Sheng Zha (Amazon) 		http://youtu.be/OH38o3T4Ffo			2021-03-24	eng	onnxcommunity-2021_03
Steering Committee, Roadmap	SteeringCommitteeUpdates: Roadmap Update	Joohoon Lee (Nvidia) 		http://youtu.be/JoFRXc9pOCQ			2021-03-24	eng	onnxcommunity-2021_03
ipu	popART: Support ONNX on IPU	Han Zhao (GraphCore-China)		http://youtu.be/8LMtU7Nxjhs			2021-03-24	eng	onnxcommunity-2021_03
Quantization	Spring Project：Multi Backend Neural Network Auto Quantization and Deployment over ONNX	Fengwei Yu (SenseTime-China)		http://youtu.be/HRPxyx_lVhc			2021-03-24	eng	onnxcommunity-2021_03
runeime	ONNX Runtime for Mobile Scenarios: From model to on-device inferencing	Tom Wildenhain (Microsoft-USA), Scott McKay (Microsoft-Australia)		http://youtu.be/ta9sBtL-4LQ			2021-03-24	eng	onnxcommunity-2021_03
paddle	ONNX on PaddlePaddle 2.0: Broader Deployment and Richer Ecosystem	Wranky Wang (Baidu-China)		http://youtu.be/ciC4pCHdlRI			2021-03-24	eng	onnxcommunity-2021_03
microcontroler	ONNX on microcontrollers	Rohit Sharma (AITechSystems-USA_CA)		http://youtu.be/cT87n24PGKQ			2021-03-24	eng	onnxcommunity-2021_03
monitoring	Monitoring and Explaining ONNX Models in Production	Krishna Gade (FiddlerAI-USA_CA)		http://youtu.be/9u4eH4s-R40			2021-03-24	eng	onnxcommunity-2021_03
client	ONNX client for Acumos	Philippe Dooze (Orange-France)		http://youtu.be/8BEmINNOw6g			2021-03-24	eng	onnxcommunity-2021_03
cloud, edge	Deploy ONNX model seamlessly across the cloud, edge, and mobile devices using MindSpore	Leon Wang (Huawei-China)		http://youtu.be/374hZaik6_k			2021-03-24	eng	onnxcommunity-2021_03
runtime, training	ONNX Runtime Training	Peng Wang (Microsoft China)		http://youtu.be/-wHzQHJLB7w			2021-03-24	eng	onnxcommunity-2021_03
intel, quantization	Quantization support for ONNX using Intel Neural Compressor (formerly named Intel Low Precision Optimization Tool)	Haihao Shen (Intel - China), Saurabh Tangri (Intel)		http://youtu.be/bOyPzPRfffU			2021-03-24	eng	onnxcommunity-2021_03
sig	Architecture/Infrastructure SIG Update	Ashwini Khade (Microsoft)		http://youtu.be/xos1s0ychMI			2021-03-24	eng	onnxcommunity-2021_03
sig	Architecture/Infrastructure SIG Update	Jacky Chen (Microsoft)		http://youtu.be/rRIdWVe_5J8			2021-03-24	eng	onnxcommunity-2021_03
sig	Operators SIG Update	Michał Karzyński (Intel), Ganesan Ramalingam (Microsoft)		http://youtu.be/OS1hWTD9TJ8			2021-03-24	eng	onnxcommunity-2021_03
sig	Converters SIG Update	Guenther Schmuelling (Microsoft), Kevin Chen (Nvidia), Chin Huang (IBM)		http://youtu.be/5SqHs2iLyQY			2021-03-24	eng	onnxcommunity-2021_03
zoo, tutorials	Model Zoo/Tutorials SIG Update	Wenbing Li (Microsoft)		http://youtu.be/HEvpM323fEg			2021-03-24	eng	onnxcommunity-2021_03
GAP	My experience implementing ONNX import for GAP processors	Martin Croome (Greenwaves Tech)		http://youtu.be/mekizqRCd-I			2021-03-24	eng	onnxcommunity-2021_03
Visualization	Visualizing ONNX models' internal data: Key thing to look for?	Mina Amiri (Zetane)		http://youtu.be/K4hjaVjiw3I			2021-03-24	eng	onnxcommunity-2021_03
Steering Committee, Roadmap	SteeringCommitteeUpdates: ONNX Steering Committee Welcome, Progress, Roadmap, Release 	Prasanth Pulavarthi (Microsoft), Alexandre Eichenberger (IBM), Wenming, Rajeev Nalawadi (Intel)		https://youtu.be/HRW77NfwAUM			2021-10-21	eng	onnxcommunity-2021_10
runtime, browser	ONNX Runtime Web: running your machine learning model in browser	Emma Ning (Microsoft)		https://youtu.be/0dskvE4IvGM			2021-10-21	eng	onnxcommunity-2021_10
standard	ONNX as standard format for institution with legacy	Haixuan Xavier Tao (Banque France)		https://youtu.be/BmI4Tdn8EFs			2021-10-21	eng	onnxcommunity-2021_10
ibm	ONNX and the AI on IBM Z client journey	Elpida Tzortzatos (IBM), Andrew M. Sica (IBM)		https://youtu.be/et--BlfJlYI			2021-10-21	eng	onnxcommunity-2021_10
Intel, INC, Quantization	Intel Neural Compressor: A Scalable Quantization Tool for ONNX Models	Mengni Wang (Intel)		https://youtu.be/Irk9UIcsCng			2021-10-21	eng	onnxcommunity-2021_10
cann, interoperability, performance	Ascend CANN and ONNX : inference interoperability for better performance	Zhipeng Huang (Huawei)		https://youtu.be/rAit0evmJTg			2021-10-21	eng	onnxcommunity-2021_10
intel, xpu	Intel OneAPI software stack: ONNX Support for xPU hardware	Kiefer Kuah (Intel)		https://youtu.be/caiPAg9ybTM			2021-10-21	eng	onnxcommunity-2021_10
paddle	Boosting PaddlePaddle Deployment in Industry	Jiajun Jiang (Baidu)		https://youtu.be/ysDnZ_tgRhM			2021-10-21	eng	onnxcommunity-2021_10
auditing, onnx	Auditing considerations for ONNX models and benchmarking with QuSandbox	Sri Krishnamurthy (QuantUniversity)		https://youtu.be/mKMS_apB1VQ			2021-10-21	eng	onnxcommunity-2021_10
TVM	TVM: Dynamic shapes, control flow, and quantization with a compiler	Jason Knight (OctoML), Andrew Luo (OctoML)		https://youtu.be/JzHNyDcGUHI			2021-10-21	eng	onnxcommunity-2021_10
Openvino	Place of ONNX in OpenVINO ecosystem	Sergey Lyalin (Intel)		https://youtu.be/QsiQcTH4uGw			2021-10-21	eng	onnxcommunity-2021_10
Triton, onnx, Runtime	Triton & ONNX Runtime	Ashwini Khade (Microsoft), Mahan Salehi (Nvidia)		https://youtu.be/7l-wZz0qq4k			2021-10-21	eng	onnxcommunity-2021_10
sig	Architecture/Infrastructure SIG Update	Ashwini Khade (Microsoft)		https://youtu.be/PpFveWQAhWM			2021-10-21	eng	onnxcommunity-2021_10
sig	Operators SIG Update	Michal Karzynski (Intel), Ganesan Ramalingam (Microsoft)		https://youtu.be/ZYT-AR5ZVr4			2021-10-21	eng	onnxcommunity-2021_10
sig	Converters SIG Update	Chin Huang (IBM), Guenther Schmuelling (Microsoft), Kevin Chen (Nvidia)		https://youtu.be/W_089tiW86Y			2021-10-21	eng	onnxcommunity-2021_10
zoo, tutorials	Model Zoo / Tutorials SIG Update	Wenbing Li (Microsoft), Mark Hamilton (Microsoft)		https://youtu.be/0tuIJpMMLw8			2021-10-21	eng	onnxcommunity-2021_10
Pre-processing, wg	Pre-processing WG	Joaquin Anton (Nvidia)		https://youtu.be/bomYGXt8Y3U			2021-10-21	eng	onnxcommunity-2021_10
